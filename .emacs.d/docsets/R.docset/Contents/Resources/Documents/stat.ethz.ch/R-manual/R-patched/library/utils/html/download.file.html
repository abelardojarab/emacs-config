<html><!-- Mirrored from stat.ethz.ch/R-manual/R-patched/library/utils/html/download.file.html by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 04 May 2016 16:39:51 GMT --><!-- Added by HTTrack --><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><!-- /Added by HTTrack -->
<title>Download File from the Internet</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" type="text/css" href="R.css">
</head><body>

<table width="100%" summary="page for download.file {utils}"><tbody><tr><td>download.file {utils}</td><td style="text-align: right;">R Documentation</td></tr></tbody></table>

<h2>Download File from the Internet</h2>

<h3>Description</h3>

<p>This function can be used to download a file from the Internet.
</p>


<h3>Usage</h3>

<pre>download.file(url, destfile, method, quiet = FALSE, mode = "w",
              cacheOK = TRUE,
              extra = getOption("download.file.extra"))
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tbody><tr valign="top"><td><code>url</code></td>
<td>
<p>A character string naming the URL of a resource to be
downloaded.</p>
</td></tr>
<tr valign="top"><td><code>destfile</code></td>
<td>
<p>A character string with the name where the downloaded
file is saved.  Tilde-expansion is performed.</p>
</td></tr>
<tr valign="top"><td><code>method</code></td>
<td>
<p>Method to be used for downloading files.  Current
download methods are <code>"internal"</code>, <code>"wininet"</code> (Windows
only) <code>"libcurl"</code>, <code>"wget"</code> and <code>"curl"</code>, and there
is a value <code>"auto"</code>: see ‘Details’ and ‘Note’.
</p>
<p>The method can also be set through the option
<code>"download.file.method"</code>: see <code><a href="../../base/html/options.html">options</a>()</code>.
</p>
</td></tr>
<tr valign="top"><td><code>quiet</code></td>
<td>
<p>If <code>TRUE</code>, suppress status messages (if any), and
the progress bar.</p>
</td></tr>
<tr valign="top"><td><code>mode</code></td>
<td>
<p>character.  The mode with which to write the file.  Useful
values are <code>"w"</code>, <code>"wb"</code> (binary), <code>"a"</code> (append) and
<code>"ab"</code>.  Only used for the <code>"internal"</code> method.
</p>
</td></tr>
<tr valign="top"><td><code>cacheOK</code></td>
<td>
<p>logical.  Is a server-side cached value acceptable?</p>
</td></tr>
<tr valign="top"><td><code>extra</code></td>
<td>
<p>character vector of additional command-line arguments for
the <code>"wget"</code> and <code>"curl"</code> methods.</p>
</td></tr>
</tbody></table>


<h3>Details</h3>

<p>The function <code>download.file</code> can be used to download a single
file as described by <code>url</code> from the internet and store it in
<code>destfile</code>.
The <code>url</code> must start with a scheme such as
<span class="samp">http://</span>, <span class="samp">https://</span>, <span class="samp">ftp://</span> or <span class="samp">file://</span>.
</p>
<p>If <code>method = "auto"</code> is chosen (the default), method
<code>"libcurl"</code> is chosen for <span class="samp">https://</span> and <span class="samp">ftps://</span> URLs
provided <code><a href="../../base/html/capabilities.html">capabilities</a>("libcurl")</code> is true, and the
internal method is chosen for <span class="samp">file://</span> URLs and for the others
provided <code><a href="../../base/html/capabilities.html">capabilities</a>("http/ftp")</code> is true (which it
almost always is).

</p>
<p>Support for method <code>"libcurl"</code> is optional: use
<code><a href="../../base/html/capabilities.html">capabilities</a>("libcurl")</code> to see if it is supported on
your build.  (It uses an external library of that name
(http://curl.haxx.se/libcurl/) against which <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> can be compiled.)
It will usually provide (non-blocking) access to
<span class="samp">https://</span> and <span class="samp">ftps://</span> URLs.  There is support for
simultaneous downloads, so <code>url</code> and <code>destfile</code> can be
character vectors of the same length greater than one.  For a single
URL and <code>quiet = FALSE</code> a progress bar is shown in interactive
use.
</p>
<p>For methods <code>"wget"</code> and <code>"curl"</code> a system call is made to
the tool given by <code>method</code>, and the respective program must be
installed on your system and be in the search path for executables.
They will block all other activity on the <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> process until they
complete: this may make a GUI unresponsive.
</p>
<p><code>cacheOK = FALSE</code> is useful for <span class="samp">http://</span> and
<span class="samp">https://</span> URLs: it will attempt to get a copy directly from the
site rather than from an intermediate cache.  It is used by
<code><a href="available.packages.html">available.packages</a></code>.
</p>
<p>The <code>"libcurl"</code> and <code>"wget"</code> methods follow <span class="samp">http://</span>
and <span class="samp">https://</span> redirections: the <code>"internal"</code> method does not.
(For method <code>"curl"</code> use argument <code>extra = "-L"</code>. To disable
redirection in <code>wget</code>, use <code>extra = "--max-redirect=0"</code>.)
(The <code>"wininet"</code> method supports some redirections but not all.)
</p>
<p>Note that <span class="samp">https://</span> URLs are
not supported by the internal method.
</p>
<p>See <code><a href="../../base/html/connections.html">url</a></code> for how <span class="samp">file://</span> URLs are interpreted,
especially on Windows.  The <code>"internal"</code> and <code>"wininet"</code>
methods do not percent-decode <span class="samp">file://</span> URLs, but the
<code>"libcurl"</code> and <code>"curl"</code> methods do: method <code>"wget"</code>
does not support them.
</p>
<p>Most methods do not percent-encode special characters such as spaces
in URLs (see <code><a href="URLencode.html">URLencode</a></code>), but it seems the
<code>"wininet"</code> method does.
</p>
<p>The remaining details apply to the <code>"internal"</code>, <code>"wininet"</code>
and <code>"libcurl"</code> methods only.
</p>
<p>The timeout for many parts of the transfer can be set by the option
<code>timeout</code> which defaults to 60 seconds.
</p>
<p>The level of detail provided during transfer can be set by the
<code>quiet</code> argument and the <code>internet.info</code> option: the details
depend on the platform and scheme.  For the <code>"internal"</code> method
setting option <code>internet.info</code> to 0 gives all available details,
including all server responses.  Using 2 (the default) gives only
serious messages, and 3 or more suppresses all messages.  For the
<code>"libcurl"</code> method values of the option less than 2 give verbose
output.
</p>
<p>A progress bar tracks the transfer.  If the file length is known, an
equals sign represents 2% of the transfer completed: otherwise a dot
represents 10Kb.
</p>
<p>Code written to download binary files must use <code>mode = "wb"</code>, but
the problems incurred by a text transfer will only be seen on Windows.
</p>


<h3>Value</h3>

<p>An (invisible) integer code, <code>0</code> for success and non-zero for
failure.  For the <code>"wget"</code> and <code>"curl"</code> methods this is the
status code returned by the external program.  The <code>"internal"</code>
method can return <code>1</code>, but will in most cases throw an error.
</p>


<h3>Setting Proxies</h3>

<p>The next two paragraphs apply to the internal code only.
</p>
<p>Proxies can be specified via environment variables.
Setting <span class="env">no_proxy</span> to <code>*</code> stops any proxy being tried.
Otherwise the setting of <span class="env">http_proxy</span> or <span class="env">ftp_proxy</span>
(or failing that, the all upper-case version) is consulted and if
non-empty used as a proxy site.  For FTP transfers, the username
and password on the proxy can be specified by <span class="env">ftp_proxy_user</span>
and <span class="env">ftp_proxy_password</span>.  The form of <span class="env">http_proxy</span>
should be <code>http://proxy.dom.com/</code> or
<code>http://proxy.dom.com:8080/</code> where the port defaults to
<code>80</code> and the trailing slash may be omitted. For
<span class="env">ftp_proxy</span> use the form <code>ftp://proxy.dom.com:3128/</code>
where the default port is <code>21</code>.  These environment variables
must be set before the download code is first used: they cannot be
altered later by calling <code><a href="../../base/html/Sys.setenv.html">Sys.setenv</a></code>.
</p>
<p>Usernames and passwords can be set for HTTP proxy transfers via
environment variable <span class="env">http_proxy_user</span> in the form
<code>user:passwd</code>.  Alternatively, <span class="env">http_proxy</span> can be of the
form <code>http://user:pass@proxy.dom.com:8080/</code> for compatibility
with <code>wget</code>.  Only the HTTP/1.0 basic authentication scheme is
supported.
</p>
<p>Much the same scheme is supported by <code>method = "libcurl"</code>, including
<span class="env">no_proxy</span>, <span class="env">http_proxy</span> and <span class="env">ftp_proxy</span>, and for the last
two a contents of <code>[user:password@]machine[:port]</code> where the
parts in brackets are optional.  See
http://curl.haxx.se/libcurl/c/libcurl-tutorial.html for details.
</p>


<h3>Secure URLs</h3>

<p>Methods which access <span class="samp">https://</span> and <span class="samp">ftps://</span> URLs should
try to verify their certificates.  This is usually done using the CA
root certificates installed by the OS (although we have seen instances
in which these got removed rather than updated). For further information
see http://curl.haxx.se/docs/sslcerts.html.
</p>
<p>This is an issue for <code>method = "libcurl"</code> on Windows, where the
OS does not provide a suitable CA certificate bundle, so by default on
Windows certificates are not verified.  To turn verification on, set
environment variable <span class="env">CURL_CA_BUNDLE</span> to the path to a certificate
bundle file, usually named ‘<span class="file">ca-bundle.crt</span>’ or
‘<span class="file">curl-ca-bundle.crt</span>’.  (This is normally done for a binary
installation of <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span>, which installs
‘<span class="file"><var>R_HOME</var>/etc/curl-ca-bundle.crt</span>’ and sets
<span class="env">CURL_CA_BUNDLE</span> to point to it if that environment variable is not
already set.)  For an updated certificate bundle, see
http://curl.haxx.se/docs/sslcerts.html.
Currently one can download a copy from
https://raw.githubusercontent.com/bagder/ca-bundle/master/ca-bundle.crt
and set <span class="env">CURL_CA_BUNDLE</span> to the full path to the downloaded file.
</p>
<p>Note that the root certificates used by <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> may or may not be the same
as used in a browser, and indeed different browsers may use different
certificate bundles (there is typically a build option to choose
either their own or the system ones).
</p>


<h3>FTP sites</h3>

<p><span class="samp">ftp:</span> URLs are accessed using the FTP protocol which has a
number of variants.  One distinction is between ‘active’ and
‘(extended) passive’ modes: which is used is chosen by the
client.  The <code>"internal"</code> and <code>"libcurl"</code> method use passive
mode, and that is almost universally used by browsers.  Prior to <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span>
3.2.3 the <code>"wininet"</code> method used active mode: since it first
tries passive and then active.
</p>


<h3>Note</h3>

<p>Files of more than 2GB are supported on 64-bit builds of <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span>; they
may be truncated on some 32-bit builds.
</p>
<p>Method <code>"wget"</code> is mainly for historical compatibility, but it
and <code>"curl"</code> can be used for URLs (e.g., <span class="samp">https://</span> URLs or
those that use cookies or redirection) which the internal method does
not support and where the <code>"libcurl"</code> method is not available.
</p>
<p>Method <code>"wget"</code> can be used with proxy firewalls which require
user/password authentication if proper values are stored in the
configuration file for <code>wget</code>.
</p>
<p><code>wget</code> (http://www.gnu.org/software/wget/) is commonly
installed on Unix-alikes (but not OS X).  Windows binaries are
available from Cygwin, gnuwin32 and elsewhere.
</p>
<p><code>curl</code> (http://curl.haxx.se/) is installed on OS X and
commonly on Unix-alikes.  Windows binaries are available at that URL.
</p>


<h3>See Also</h3>

<p><code><a href="../../base/html/options.html">options</a></code> to set the <code>HTTPUserAgent</code>, <code>timeout</code>
and <code>internet.info</code> options used by some of the methods.
</p>
<p><code><a href="../../base/html/connections.html">url</a></code> for a finer-grained way to read data from URLs.
</p>
<p><code><a href="url.show.html">url.show</a></code>, <code><a href="available.packages.html">available.packages</a></code>,
<code><a href="download.packages.html">download.packages</a></code> for applications.
</p>
<p>Contributed package RCurl provides more comprehensive
facilities to download from URLs.
</p>

<hr><div style="text-align: center;">[Package <em>utils</em> version 3.2.3 <a href="00Index.html">Index</a>]</div>

<!-- Mirrored from stat.ethz.ch/R-manual/R-patched/library/utils/html/download.file.html by HTTrack Website Copier/3.x [XR&CO'2014], Wed, 04 May 2016 16:39:51 GMT -->

</body></html>